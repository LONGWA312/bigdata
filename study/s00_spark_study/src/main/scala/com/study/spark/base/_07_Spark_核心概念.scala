package com.study.spark.base

/**
 * Executor 与 Core
    Spark Executor 是集群中运行在工作节点（Worker）中的一个 JVM 进程，是整个集群中的专门用于计算的节点。
    在提交应用中，可以提供参数指定计算节点的个数，以及对应的资源。
    这里的资源一般指的是工作节点 Executor 的内存大小和使用的虚拟 CPU 核（Core）数量

    应用程序相关启动参数如下：
    名称                  说明
    --num-executors     配置 Executor 的数量
    --executor-memory   配置每个 Executor 的内存大小
    --executor-cores    配置每个 Executor 的虚拟 CPU core 数量


 * 并行度（Parallelism）
    在分布式计算框架中一般都是多个任务同时执行，由于任务分布在不同的计算节点进行计算，所以能够真正地实现多任务并行执行，
    记住，这里是并行，而不是并发。这里我们将整个集群并行执行任务的数量称之为并行度。
    那么一个作业到底并行度是多少呢？
    这个取决于框架的默认配置。应用程序也可以在运行过程中动态修改。


 * 有向无环图（DAG）
        大数据计算引擎框架我们根据使用方式的不同一般会分为四类，
            其中第一类就是Hadoop 所承载的 MapReduce,它将计算分为两个阶段，分别为 Map 阶段 和 Reduce 阶段。
            对于上层应用来说，就不得不想方设法去拆分算法，甚至于不得不在上层应用实现多个 Job的串联，以完成一个完整的算法，例如迭代计算。
            由于这样的弊端，催生了支持 DAG 框架的产生。
            因此，支持 DAG 的框架被划分为第二代计算引擎。
            如 Tez 以及更上层的Oozie。
            这里我们不去细究各种 DAG 实现之间的区别，不过对于当时的 Tez 和 Oozie 来说，大多还是批处理的任务。
            接下来就是以 Spark 为代表的第三代的计算引擎。第三代计算引擎的特点主要是 Job 内部的 DAG 支持（不跨越 Job），以及实时计算。

        这里所谓的有向无环图，并不是真正意义的图形，而是由 Spark 程序直接映射成的数据流的高级抽象模型。
        简单理解就是将整个程序计算的执行过程用图形表示出来,这样更直观，更便于理解，可以用于表示程序的拓扑结构

        DAG（Directed Acyclic Graph）有向无环图是由点和线组成的拓扑图形，该图形具有方向，不会闭环。

 */
object _07_Spark_核心概念 {

}
